<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: https://ogp.me/ns#">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="color-scheme" content="light dark">
  
  <title>numpy实现线性回归模型 - 黄阿信</title>
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    <link rel='manifest' href='/manifest.json'>
  

  
  
  
  <meta property="og:title" content="numpy实现线性回归模型 - 黄阿信" />
  
  <meta property="og:type" content="article" />
  
  <meta property="og:url" content="https://yalexin.gitee.io/2022/03/25/numpy%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/index.html" />
  
  <meta property="og:image" content="/favicon.png" />
  
  <meta property="og:article:published_time" content="2022-03-25T14:35:43.000Z" />
  
  <meta property="og:article:author" content="YaleXin" />
  
  

  
<link rel="stylesheet" href="/css/var.css">

  
<link rel="stylesheet" href="/css/main.css">

  
<link rel="stylesheet" href="/css/typography.css">

  
<link rel="stylesheet" href="/css/code-highlighting.css">

  
<link rel="stylesheet" href="/css/components.css">

  
<link rel="stylesheet" href="/css/nav.css">

  
<link rel="stylesheet" href="/css/paginator.css">

  
<link rel="stylesheet" href="/css/footer.css">

  
<link rel="stylesheet" href="/css/post-list.css">

  
  
<link rel="stylesheet" href="/css/rainbow-banner.css">

  
  
  
<link rel="stylesheet" href="/css/toc.css">

  
  
  
  
  
<link rel="stylesheet" href="/css/post.css">

  
  
  
  
  

  
</head>
    <body
        data-color-scheme="auto"
        data-uppercase-categories="true"
        
        data-rainbow-banner="true"
        data-rainbow-banner-shown="auto"
        data-rainbow-banner-month="6"
        data-rainbow-banner-colors="#e50000,#ff8d00,#ffee00,#008121,#004cff,#760188"
        
        data-config-root="/"
        
        data-toc="true"
        data-toc-max-depth="2"
        
        
    >
        <nav id="theme-nav">
    <div class="inner">
        <a class="title" href="/">Blog</a>
        <div class="nav-arrow"></div>
        <div class="nav-items">
            <a class="nav-item nav-item-home" href="/">Home</a>
            
            
            <a class="nav-item" href="/archives">Archives</a>
            
            
            
            <a class="nav-item" href="/friends">Friends</a>
            
            
            
            <a class="nav-item" href="/projects">Projects</a>
            
            
            
            <a class="nav-item" href="/about">About</a>
            
            
            
            <a class="nav-item nav-item-github nav-item-icon" href="https://github.com/MrWillCom" target="_blank" aria-label="GitHub">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-codepen nav-item-icon" href="https://codepen.io/mrwillcom" target="_blank" aria-label="CodePen">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-patreon nav-item-icon" href="https://www.patreon.com/MrWillCom" target="_blank" aria-label="Patreon">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-mastodon nav-item-icon" href="https://noc.social/@MrWillCom" target="_blank" aria-label="Mastodon">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-discord nav-item-icon" href="https://discord.gg/UKuFDjcfY8" target="_blank" aria-label="Discord">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-search nav-item-icon" href="/search" target="_blank" aria-label="Search">&nbsp;</a>
            
            
        </div>
    </div>
</nav>
        
<article class="post">
    <div class="meta">
        
        <div class="categories text-uppercase">
        
            <a href="/categories/机器学习/">机器学习</a>
        
        </div>
        

        
        <div class="date" id="date">
            <span>March</span>
            <span>25,</span>
            <span>2022</span>
        </div>
        

        <h1 class="title">numpy实现线性回归模型</h1>
    </div>

    <div class="divider"></div>

    <div class="content">
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>生活中常常遇到线性模型的例子，例如房子的价格与占地面积几乎是呈线性，它还可能和卧室数量相关；又如一个学生是否具备获取奖学金资格与学生成绩、参与竞赛经历、班干部任职经历都相关；又如一个大学生是否能够在大学中脱单，与个人相貌、为人处事能力、生活习惯都有联系。</p>
<a id="more"></a>

<h2 id="相关原理"><a href="#相关原理" class="headerlink" title="相关原理"></a>相关原理</h2><p>以预测房子价格为例，如果将房子面积<code>x1</code>、卧室数量<code>x2</code>作为特征，房子价格为目标，则可以表示为：</p>
<p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220325230950.png" alt></p>
<p>式子中的<code>w</code>代表相应的特征权重，<code>b</code>代表偏置。</p>
<p>用向量可以表示为：</p>
<p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220325232055.png" alt></p>
<p>而我们的目标是对于给定数据集，我们求出最符合的参数<code>w1</code>和<code>w2</code>，以及<code>b</code>，使得模型很好地贴近数据集，我们该如何度量我们的模型是否和数据集贴近呢？我们这里平方差来表示二者的差距，计算该平方差的函数我们称之为损失函数，我们的样本的预测值为<code>y_hat</code>，真实值为<code>y</code>，则损失函数如下：</p>
<p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220325232645.png" alt></p>
<p>上面的常数<code>1/2</code>并不是硬性要求，只是为了方便后面求导使得系数变为<code>1</code>。</p>
<p>因此问题转变成找到一组参数，使得所有样本的损失和变得最小，即</p>
<p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220325233600.png" alt></p>
<p>实际上也是在求上述函数的极小值。为了方便运算，我们可以将参数<code>w</code>和<code>b</code>合并，并在<code>x</code>右边增加一列：</p>
<p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220326103156.png" alt></p>
<p>即损失函数又可以表示为：</p>
<p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220326082005.png" alt></p>
<p>小学二年级的数学老师告诉我们，这个是关于自变量<code>W*</code>（注意，这里的<code>x</code>和<code>y</code>都是常量）的二次函数，有极值，那我们该怎么求解？数学老师继续告诉我们，二次函数极值可以利用公式！当然也可以使用梯度下降分析法，因为有些模型不可以用公式直接求解极值！</p>
<p>梯度下降分析法参数更新方式是：<code>w = w - learning_rate * grad</code>，<code>grad</code>是在该点的梯度，即导数（可以粗略地称为导数，但是严格来说这样子的说法是错误的）</p>
<p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220326085926.png" alt></p>
<p>如上图所示，对于左边的点，其导数为负数，减去一个负数（<code>learning_rate</code>我们称之为学习率，是正数）后其值增大，即经过更新后，自变量<code>w</code>往右边走了一段距离，对于右边的，更新后自变量往左边走了一段距离，最终我们的<code>w</code>将趋于<code>1.0</code>，即极值点附近。</p>
<p>损失函数对<code>W</code>求导为：</p>
<p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220326093933.png" alt></p>
<h2 id="回归实现"><a href="#回归实现" class="headerlink" title="回归实现"></a>回归实现</h2><p>简单起见，我们假设只有一个特征，即只有一个<code>x</code>，而不是有<code>x1,x2,...</code>我们首先生成一组线性数据，为了更符合实际，我们加入随机偏差：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data</span><span class="params">()</span>:</span></span><br><span class="line">    x = np.linspace(<span class="number">-20</span>, <span class="number">20</span>, <span class="number">50</span>)</span><br><span class="line">    y = <span class="number">2</span>*x + <span class="number">3</span> + np.random.randn(len(x)) * <span class="number">3</span></span><br><span class="line">    x = x.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">    y = y.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure>

<p>然后初始化我们的参数<code>w,b</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init</span><span class="params">()</span>:</span></span><br><span class="line">    w, b = np.random.randn(), np.random.randn()</span><br><span class="line">    <span class="comment"># 参数合并</span></span><br><span class="line">    <span class="keyword">return</span> np.array([[w],</span><br><span class="line">                     [b]])</span><br></pre></td></tr></table></figure>

<p>定义误差函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l</span><span class="params">(W, X, y)</span>:</span></span><br><span class="line">    WX = np.dot(X, W) - y</span><br><span class="line">    <span class="keyword">return</span> WX ** <span class="number">2</span> / <span class="number">2.0</span></span><br></pre></td></tr></table></figure>

<p>定义损失函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(W, X, y)</span>:</span></span><br><span class="line">    l_value = l(W, X, y)</span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> np.sum(l_value) / n</span><br></pre></td></tr></table></figure>

<p>梯度下降法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span><span class="params">(W, X, y)</span>:</span></span><br><span class="line">    n = y.shape[<span class="number">0</span>]</span><br><span class="line">    A = np.dot(X, W) - y</span><br><span class="line">    <span class="keyword">return</span> np.dot(X.T, A) / n</span><br></pre></td></tr></table></figure>

<p>开始我们的训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    learning_rate, epoch = <span class="number">0.01</span>, <span class="number">100</span></span><br><span class="line">    W = init()</span><br><span class="line">    x, y = data()</span><br><span class="line">    one = np.ones((x.shape[<span class="number">0</span>],<span class="number">1</span>))</span><br><span class="line">    X = np.c_[x, one]</span><br><span class="line">    loss_x, loss_y = np.zeros((epoch, <span class="number">1</span>)), np.zeros((epoch, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">        loss_value = loss(W, X, y)</span><br><span class="line">        print(<span class="string">"epoch = "</span>, i, <span class="string">"loss = "</span>, loss_value)</span><br><span class="line">        loss_x[i] = i</span><br><span class="line">        loss_y[i] = loss_value</span><br><span class="line">        </span><br><span class="line">        grad = gradient_descent(W, X, y)</span><br><span class="line">        W = W - learning_rate * grad</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.scatter(x, y)</span><br><span class="line">    plt.plot(X[:, <span class="number">0</span>], np.dot(X, W), color=<span class="string">'red'</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">"loss"</span>)</span><br><span class="line">    plt.plot(loss_x, loss_y)</span><br></pre></td></tr></table></figure>

<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="https://qiniu.yalexin.top/QQ%E6%88%AA%E5%9B%BE20220326103436.png" alt></p>
<p>可以发现，拟合效果还是挺不错的，损失值下降得也挺快，前面的急剧下降是因为我们是随机初始化的参数，该参数对应的导数可能比较大，因此更新得比较快。</p>

    </div>

    
    <div class="about">
        <h1>About this Post</h1>
        <div class="details">
            <p>This post is written by YaleXin, licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0" target="_blank" rel="noopener">CC BY-NC 4.0</a>.</p>
        </div>
        
        <p class="tags">
            
            <i class="icon"></i>
            <a href="/tags/线性回归/" class="tag">#线性回归</a>
        </p>
        
    </div>
    

    <div class="container post-prev-next">
        
        <a href="/2022/04/11/numpy%E5%AE%9E%E7%8E%B0%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/" class="next">
            <div>
                <div class="text">
                    <p class="label">Next</p>
                    <h3 class="title">numpy实现多项式回归模型</h3>
                </div>
            </div>
        </a>
        
        
        <a href="/2022/02/12/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%8D/" class="prev">
            <div>
                <div class="text">
                    <p class="label">Previous</p>
                    <h3 class="title">Git学习笔记之搭建私服</>
                </div>
            </div>
        </a>
        
    </div>

    
        
        
    
</article>

        <footer>
    <div class="inner">
        <div class="links">
            
            <div class="group">
                <h2 class="title">Blog</h2>
                
                <a href="/" class="item">Blog</a>
                
                <a href="/archives" class="item">Archives</a>
                
                <a href="/tags" class="item">Tags</a>
                
                <a href="/categories" class="item">Categories</a>
                
                <a href="/search" class="item">Search</a>
                
                <a href="/friends" class="item">Friends</a>
                
                <a href="/projects" class="item">Projects</a>
                
                <a href="/resume" class="item">Resume</a>
                
                <a href="/about" class="item">About</a>
                
                <a href="/atom.xml" class="item">RSS</a>
                
            </div>
            
            <div class="group">
                <h2 class="title">Projects</h2>
                
                <a href="https://github.com/MrWillCom/rsa-cli" target="_blank" rel="noopener" class="item">RSA CLI</a>
                
                <a href="https://github.com/MrWillCom/hexo-theme-cupertino" target="_blank" rel="noopener" class="item">Hexo Theme Cupertino</a>
                
                <a href="https://github.com/MrWillCom/a-calendar" target="_blank" rel="noopener" class="item">A Calendar</a>
                
                <a href="https://github.com/MrWillCom/auto-mirroring-bucket" target="_blank" rel="noopener" class="item">Auto Mirroring Bucket</a>
                
            </div>
            
            <div class="group">
                <h2 class="title">Me</h2>
                
                <a href="https://github.com/MrWillCom" target="_blank" rel="noopener" class="item">GitHub</a>
                
                <a href="https://codepen.io/mrwillcom" target="_blank" rel="noopener" class="item">CodePen</a>
                
                <a href="https://www.patreon.com/MrWillCom" target="_blank" rel="noopener" class="item">Patreon</a>
                
                <a href="https://noc.social/@MrWillCom" target="_blank" rel="noopener" class="item">Mastodon</a>
                
                <a href="https://discord.gg/UKuFDjcfY8" target="_blank" rel="noopener" class="item">Discord</a>
                
                <a href="mailto:mr.will.com@outlook.com" class="item">Email</a>
                
            </div>
            
        </div>
        <span>&copy; 2024 YaleXin<br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> </span>
        
        
            <br>
            <div class="color-scheme-toggle" role="radiogroup" id="theme-color-scheme-toggle">
                <label>
                    <input type="radio" value="light">
                    <span>Light</span>
                </label>
                <label>
                    <input type="radio" value="dark">
                    <span>Dark</span>
                </label>
                <label>
                    <input type="radio" value="auto">
                    <span>Auto</span>
                </label>
            </div>
        
    </div>
</footer>


        
<script src="/js/main.js"></script>

        
        
        

        
        <script src="https://unpkg.com/scrollreveal"></script>
        <script>
            window.addEventListener('load', () => {
                ScrollReveal({ delay: 250, reset: true, easing: 'cubic-bezier(0, 0, 0, 1)' })
                ScrollReveal().reveal('.post-list-item .cover-img img')
                ScrollReveal().reveal('.post-list-item, .card, .content p img, .content .block-large img', { distance: '60px', origin: 'bottom', duration: 800 })
            })
        </script>
        
    </body>
</html>